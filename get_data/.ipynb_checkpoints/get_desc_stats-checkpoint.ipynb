{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm connected\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "#K. David Roell CFPB 7/12/16\n",
    "#expands data selection for quality edits to include context for developing statistical approaches\n",
    "#will attemtp to segment mortgage market participants by loan activity by:\n",
    "#volume/count of lending, income of applicants, securitization, property type and other factors\n",
    "##############\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "matplotlib.style.use('ggplot')\n",
    "#from macro_sql import Q076 \n",
    "with open('quality_sql.json') as f: #FIXME change to quality_sql.json and refactor the rest of code\n",
    "    edit_sql = json.load(f)\n",
    "    \n",
    "#parameter format for local use #consider changing hmdamaster to roellk if db changes cause a fail\n",
    "params = {\n",
    "'dbname':'hmdamaster',\n",
    "'user':'roellk',\n",
    "'password':'',\n",
    "'host':'localhost',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(**params)\n",
    "    cur = conn.cursor()\n",
    "    print(\"i'm connected\")\n",
    "\n",
    "except psycopg2.Error as e: #if database connection results in an error print the following\n",
    "    print(\"I am unable to connect to the database: \", e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def desc_stats_geo(table='hmdalar2014', field= 'amount', where_max=None, where_min=None, geo_level=None):\n",
    "    \"\"\"generates SQL statement to get descriptive statistics for a LAR field and group them by a geography if one is specified.\n",
    "    min and max can also be specified to focus analysis on a specific numeric range\"\"\"\n",
    "    #FIXME change default values to none and implement value error\n",
    "    #establish geo level for grouping\n",
    "    if geo_level == 'msa':\n",
    "        geo_sql = 'msa AS msa,'\n",
    "        geo_group = ',msa'\n",
    "    elif geo_level == 'state':\n",
    "        geo_sql = 'state AS state,'\n",
    "        geo_group = ',state'\n",
    "    elif geo_level == 'county':\n",
    "        geo_sql = 'CONCAT(state,county) AS county,'\n",
    "        geo_group = ',CONCAT(state,county)'\n",
    "    elif geo_level == 'tract':\n",
    "        geo_sql = 'CONCAT(state,county,tract) AS tract,'\n",
    "        geo_group = ',CONCAT(state,county,tract)'\n",
    "    else:\n",
    "        geo_sql = ''\n",
    "        geo_group = ''\n",
    "        \n",
    "    base_sql = \"\"\"SELECT year, {geo_level} COUNT({field}) AS count_loans, SUM({field}::INT) AS sum_amt, AVG({field}::INT) AS avg_{field}, \n",
    "    STDDEV({field}::INT) AS std_{field}, MIN({field}::INT) AS min_{field}, \n",
    "    MAX({field}::INT) AS max_{field}\"\"\".format(field=field, geo_level=geo_sql)\n",
    "    table_sql = \"\\nFROM {table}\\n\".format(table=table) \n",
    "    where_sql = \"WHERE property_type = '1' AND loan_purpose = '1' AND agency != '7' AND {field} NOT ILIKE '%NA%' \".format(field=field)\n",
    "    if where_max:\n",
    "        where_sql = where_sql + \" AND {field}::INT < \".format(field=field) + str(where_max)\n",
    "    if where_min:\n",
    "        where_sql = where_sql + \" AND {field}::INT > \".format(field=field) + str(where_min)\n",
    "    group_sql = \"\"\" GROUP BY year {geo_level}\"\"\".format(geo_level=geo_group)\n",
    "    \n",
    "    return_sql = base_sql + table_sql + where_sql + group_sql\n",
    "    print(return_sql)\n",
    "    return return_sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#get descriptive statistics for the field named\n",
    "#FIXME add an optional set of limits to look at sub distributions min/max= 10/600? set by cumulative probability\n",
    "def get_desc_stats(geo_level=None, field='amount', year=2014, where_max=None, where_min=None):\n",
    "    \"\"\"\"\"\"\n",
    "    #FIXME change default values to none and implement value error\n",
    "    first = True\n",
    "    while year > 2003: #loop over all years until schema change in LAR data\n",
    "        table = 'hmdalar' + str(year) #set table name for query\n",
    "        \n",
    "        print(table)\n",
    "        #cur.execute(desc_stats(table=table, field=field))        \n",
    "        cur.execute(desc_stats_geo(table=table, field=field, where_max=where_max, where_min=where_min, geo_level=geo_level))        \n",
    "        data_df = pd.DataFrame(cur.fetchall()) #convert query results to dataframe\n",
    "        col_names = [desc[0] for desc in cur.description] #pull column names from cursor\n",
    "        \n",
    "        if len(data_df.columns) == len(col_names): #verify data was returned before naming columns\n",
    "            print('setting column names')\n",
    "            data_df.columns = col_names\n",
    "        if first == True and len(data_df.columns) > 0: \n",
    "            dist_df = data_df.copy() #establish initial data frame\n",
    "            first = False\n",
    "        elif first == False and len(data_df.columns) > 0:\n",
    "            print('merging dataframes')\n",
    "            dist_df=dist_df.merge(data_df, how='outer') #merge subsequent data into initial data frame\n",
    "        else:\n",
    "            print('no data returned from query')\n",
    "        \n",
    "        #set upper and lower bounds on distribution\n",
    "        dist_df['-2STD'] = dist_df['avg_{field}'.format(field=field)] - 2*dist_df['std_{field}'.format(field=field)]\n",
    "        dist_df['+2STD'] = dist_df['avg_{field}'.format(field=field)] + 2*dist_df['std_{field}'.format(field=field)]\n",
    "        \n",
    "        print(dist_df.tail()) #print data to check results during execution\n",
    "        \n",
    "        path = '../dist_csvs/'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        year -= 1 #decrement year to select new table\n",
    "\n",
    "    dist_df.to_csv(path + '{field}_desc_stats_{geo_level}.csv'.format(field=field, geo_level=geo_level),index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get_desc_stats(geo_level='state', field='income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmdalar2014\n",
      "SELECT year, msa AS msa, COUNT(amount) AS count_loans, SUM(amount::INT) AS sum_amt, AVG(amount::INT) AS avg_amount, \n",
      "    STDDEV(amount::INT) AS std_amount, MIN(amount::INT) AS min_amount, \n",
      "    MAX(amount::INT) AS max_amount\n",
      "FROM hmdalar2014\n",
      "WHERE property_type = '1' AND loan_purpose = '1' AND agency != '7' AND amount NOT ILIKE '%NA%'  GROUP BY year ,msa\n",
      "setting column names\n",
      "     year    msa  count_loans   sum_amt            avg_amount  \\\n",
      "404  2014  NA          572701  97012165  169.3940904590702653   \n",
      "405  2014  14454        21262   8403251  395.2239206095381432   \n",
      "406  2014  29820        16387   3591352  219.1586013303228169   \n",
      "407  2014  24580         3955    577626  146.0495575221238938   \n",
      "408  2014  15540         2815    631402  224.2991119005328597   \n",
      "\n",
      "              std_amount  min_amount  max_amount                  -2STD  \\\n",
      "404     269.324771537868           1       99999  -369.2554526166657347   \n",
      "405     342.076011019465           1       12000  -288.9281014293918568   \n",
      "406     175.645789109022           1        3569  -132.1329768877211831   \n",
      "407  95.4934768403082946           1        1950   -44.9373961584926954   \n",
      "408     108.892907472059           1        1100     6.5132969564148597   \n",
      "\n",
      "                     +2STD  \n",
      "404   708.0436335348062653  \n",
      "405  1079.3759426484681432  \n",
      "406   570.4501795483668169  \n",
      "407   337.0365112027404830  \n",
      "408   442.0849268446508597  \n",
      "hmdalar2013\n",
      "SELECT year, msa AS msa, COUNT(amount) AS count_loans, SUM(amount::INT) AS sum_amt, AVG(amount::INT) AS avg_amount, \n",
      "    STDDEV(amount::INT) AS std_amount, MIN(amount::INT) AS min_amount, \n",
      "    MAX(amount::INT) AS max_amount\n",
      "FROM hmdalar2013\n",
      "WHERE property_type = '1' AND loan_purpose = '1' AND agency != '7' AND amount NOT ILIKE '%NA%'  GROUP BY year ,msa\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-020702d4107c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_desc_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeo_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'msa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-e0646e5558bc>\u001b[0m in \u001b[0;36mget_desc_stats\u001b[0;34m(geo_level, field, year, where_max, where_min)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#cur.execute(desc_stats(table=table, field=field))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc_stats_geo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeo_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeo_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#convert query results to dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcol_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#pull column names from cursor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(_cls, name, type_code, display_size, internal_size, precision, scale, null_ok)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_desc_stats(geo_level='msa', field='amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
